{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 6 LSTMs & GRU: génération de séquences\n",
    "\n",
    "_Ismaël Bonneau_\n",
    "\n",
    "Ce notebook sert uniquement à présenter nos résultats, et les bouts de code intéressants dans le cadre de ce rapport. L'intégralité du code est contenu dans le fichier tp6.py.\n",
    "\n",
    "## But\n",
    "\n",
    "Nous avons dans le notebook précédent codé un RNN from scratch et nous l'avons appliqué sur une tâche de génération de séquence. Nous allons maintenant reprendre cette tâche et utiliser à la place du RNN un LSTM et un GRU, codés from scratch.\n",
    "\n",
    "<img src=\"../images/rnn_vs_lstm.png\" width=\"500\">\n",
    "\n",
    "## Données\n",
    "\n",
    "Le jeu de données suggéré dans l'énoncé est un discours de Donald Trump. Cependant, il est beaucoup plus drôle de travailler sur le script du seigneur des anneaux. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmovieever = pd.read_csv(\"../TP4/data/lord-of-the-rings-data/lotr_scripts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérons les lignes de dialogue des 3 films du seigneur des anneaux. Nous allons garder uniquement les répliques de Gandalf, Frodon, Bilbon, Aragorn et Galadriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>char</th>\n",
       "      <th>dialog</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>FRODO</td>\n",
       "      <td>Gandalf?</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>FRODO</td>\n",
       "      <td>Oooohhh!</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>FRODO</td>\n",
       "      <td>Gimli!</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>FRODO</td>\n",
       "      <td>No, it isn't. It isn't midday yet. , The days ...</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>FRODO</td>\n",
       "      <td>What about you?</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   char                                             dialog  \\\n",
       "16          16  FRODO                                   Gandalf?           \n",
       "17          17  FRODO                                          Oooohhh!    \n",
       "20          20  FRODO                                           Gimli!     \n",
       "25          25  FRODO  No, it isn't. It isn't midday yet. , The days ...   \n",
       "30          30  FRODO                                  What about you?     \n",
       "\n",
       "                      movie  \n",
       "16  The Return of the King   \n",
       "17  The Return of the King   \n",
       "20  The Return of the King   \n",
       "25  The Return of the King   \n",
       "30  The Return of the King   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = [\"GANDALF\", \"\\xa0GANDALF\", \"GAN DALF\", 'GANDALF VOICEOVER',\n",
    "             'FRODO VOICE OVER', 'FRODO', 'SARUMAN VOICE OVER ', 'SARUMAN VOICE OVER',\n",
    "             \"ARAGORN\", 'GALADRIL', \"GALADRIEL\", 'GALADRIEL VOICE-OVER',\n",
    "             'BILBO VOICEOVER', \"BILBO\", 'GALADRIEL VOICEOVER']\n",
    "bestmovieever[bestmovieever[\"char\"].isin(characters)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On nettoie un peu les lignes de dialogue:\n",
    "\n",
    "On sépare en phrases, et on élimine les phrases trop courtes (comme \"no.\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_tags, strip_numeric\n",
    "import re\n",
    "\n",
    "CUSTOM_FILTERS = [strip_tags, strip_multiple_whitespaces, strip_numeric]\n",
    "\n",
    "hey = list(bestmovieever[bestmovieever[\"char\"].isin(characters)][\"dialog\"])\n",
    "gandalf = []\n",
    "for d in hey:\n",
    "    mdr = \" \".join(preprocess_string(d, CUSTOM_FILTERS))\n",
    "    for ahaha in mdr.split(\".\"):\n",
    "        if ahaha != \"\":\n",
    "            x = ahaha.strip()\n",
    "            if (\"!\" != x[-1]) and (\"?\" != x[-1]):\n",
    "                x = x+\".\"\n",
    "            x = re.sub(r'^ , ', '', x)\n",
    "            x = re.sub(r'^, ', '', x)\n",
    "            x = re.sub(r'^,', '', x)\n",
    "            if len(x) > 8:\n",
    "                gandalf.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Some hurts that go too deep, that have taken hold.',\n",
       " \"It's been four years to the day since Weathertop Sam.\",\n",
       " \"It's never really healed.\",\n",
       " 'Not quite.',\n",
       " \"There's room for a little more.\",\n",
       " 'Bilbo once told me his part in this tale would end.',\n",
       " 'That each of us must come and go in the telling.',\n",
       " \"Bilbo's story was now over.\",\n",
       " 'There would be no more journeys for him.',\n",
       " 'save one.',\n",
       " 'Tell me again lad, where are we going?',\n",
       " 'To the harbour Bilbo.',\n",
       " 'The elves have accorded you a special honour.',\n",
       " 'A place on the last ship to leave Middle Earth.',\n",
       " 'Frodo, any chance of seeing that old Ring of mine again? The one I gave you?',\n",
       " 'Show yourself.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gandalf[18:34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous allons travailler au niveau des caractères. \n",
    "\n",
    "il faut encoder chaque caractère sous forme d'id numérique (entier). On associe donc à chaque caractère un entier. le 0 servira au padding, et l'id _nb caractères+1_ servira à signaler la fin de séquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longueur max. de sequence: 257\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "max_len = len(gandalf[np.argmax([len(s) for s in gandalf])]) + 1 # +1 pour la fin de séquence\n",
    "print(\"longueur max. de sequence: {}\".format(max_len))\n",
    "\n",
    "LETTRES = set()\n",
    "for phrase in gandalf:\n",
    "    LETTRES.update(list(phrase))\n",
    "LETTRES.update(list(string.ascii_letters))\n",
    "id2lettre = dict(zip(range(1, len(LETTRES)+1),LETTRES))\n",
    "id2lettre[0]= '' # NULL CHARACTER for padding\n",
    "id2lettre[len(LETTRES)+1] = \"EOF\"\n",
    "lettre2id = dict(zip(id2lettre.values(), id2lettre.keys()))\n",
    "\n",
    "def normalize(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if c in LETTRES)\n",
    "def string2code(s):\n",
    "    base = [lettre2id[c] for c in normalize(s)] + [lettre2id[\"EOF\"]]\n",
    "    if len(base) < max_len:\n",
    "        padding = [0] * (max_len - len(base))\n",
    "    else:\n",
    "        padding = []\n",
    "    return base + padding + [0]\n",
    "def code2string(t):\n",
    "    if type(t) != list:\n",
    "        t = t.tolist()\n",
    "    return ''.join(id2lettre[i] for i in t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple de phrase transformée en suite d'entiers:\n",
    "\n",
    "On voit que l'on a ajouté du padding (des 0) à la fin des phrases pour avoir des sequences de longueur identique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your treachery has already cost many lives.\n",
      "[41, 50, 19, 11, 64, 16, 11, 10, 60, 55, 30, 10, 11, 18, 64, 30, 60, 4, 64, 60, 57, 11, 10, 60, 34, 18, 64, 55, 50, 4, 16, 64, 39, 60, 40, 18, 64, 57, 54, 32, 10, 4, 33, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(gandalf[38])\n",
    "print(string2code(gandalf[38]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pas besoin de one-hot encoding car on va utiliser le module nn.Embeddings\n",
    "\n",
    "On utilise _np.exand_dims_ pour avoir une matrice en 3 dimensions _nb sequences x longueur sequence x dimension données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1069, 258, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.array([np.array(string2code(s)) for s in gandalf])\n",
    "data = np.expand_dims(data, axis=2)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le GRU que nous avons codé attend en entrée des matrices de taille _longueur sequence x nb sequences (batch) x dimension données_. On va donc swaper les dimensions 0 et 1 de notre array de séquences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258, 1069, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.swapaxes(data, 0, 1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà les donneés prêtes à être ingérées par le modèle!\n",
    "\n",
    "#### On définit un Dataset pour cette tâche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Dataset_RNN(Dataset):\n",
    "    \"\"\"Dataset avec la taille de batch en axis 1 au lieu de 0.\n",
    "        Pas mal pour notre RNN\"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        super(Dataset_RNN, self).__init__()\n",
    "        self.labels = torch.from_numpy(y)\n",
    "        self.data = torch.from_numpy(x).long()\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[:,index,:], self.labels[index]\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle\n",
    "\n",
    "Cette fois-ci, on introduit la supervision à chaque étape: au lieu de devoir encoder correctement une classe dans l'état ${h_T}$, le modèle doit réussir à produire ${x_t}$ à partir de ${h_{t-1}}$ à chaque étape. Chaque \"cellule\" du GRU déplié doit donc appliquer un décodeur sur l'état ${h_{t-1}}$ qu'elle reçoit en entrée.\n",
    "\n",
    "Le fait que l'on utilise des caractères rajoute une difficulté supplémentaire: il va falloir en même temps calculer une projection des caractères dans un espace continu (embedding).\n",
    "\n",
    "L'entrainement va fonctionner comme ceci:\n",
    "\n",
    "- On traite le batch de sequences avec une passe de forward.\n",
    "- On récupère l'historique des ${h_1}$, ..., ${h_{T-1}}$ calculés par le réseau.\n",
    "- On décode l'historique.\n",
    "- On calcule la loss (cross entropy) sur les valeurs décodées qui doivent correspondre à ${h_2}$, ..., ${h_{T}}$\n",
    "- On masque la loss aux endroits qui correspondent au padding pour chaque batch, et on applique la backward propagation.\n",
    "\n",
    "\n",
    "<img src=\"../images/gru.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    \"\"\"docstring for GRU\"\"\"\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(GRU, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.W_update_x = nn.Linear(input_dim, latent_dim)\n",
    "        self.W_update_h = nn.Linear(latent_dim, latent_dim)\n",
    "        \n",
    "        self.W_reset_x = nn.Linear(input_dim, latent_dim)\n",
    "        self.W_reset_h = nn.Linear(latent_dim, latent_dim)\n",
    "        \n",
    "        self.W_x = nn.Linear(input_dim, latent_dim)\n",
    "        self.W_h = nn.Linear(latent_dim, latent_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def one_step(self, x, h):\n",
    "        \"\"\" one step for one Xt and Ht-1 \"\"\"\n",
    "        zt = self.sigmoid(self.W_update_x(x) + self.W_update_h(h))\n",
    "        rt = self.sigmoid(self.W_reset_x(x) + self.W_reset_h(h))\n",
    "        ht = (1 - zt) * h + zt * self.tanh(self.W_x(x) + self.W_h(rt * h))\n",
    "        return ht\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\" forward on the whole sequence \"\"\"\n",
    "        historique = []\n",
    "        if h is None:\n",
    "            ht = torch.zeros(x.size()[1], self.latent_dim)\n",
    "        for xt in x:\n",
    "            # ht: (batch x latent)\n",
    "            ht = self.one_step(xt, ht)\n",
    "            historique.append(ht)\n",
    "        return historique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour la projection dans un embedding de caractères:\n",
    "\n",
    "On se sert de la classe _nn.Embedding_ de pytorch. Elle permet de créer une look-up table et de retourner automatiquement les embeddings à partir d'un vecteur d'indices plutôt qu'à partir de one-hot vectors. Ainsi, pas besoin pour nous de passer nos données en one_hot.\n",
    "\n",
    "exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character_level_encoder(torch.nn.Module):\n",
    "    \"\"\" projette les caractères dans un embedding \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Character_level_encoder, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) #apprendre des embeddings de caractère en même temps\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avant projection:  (258, 1069, 1)\n",
      "apres projection espace embedded:  torch.Size([258, 1069, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"avant projection: \", data.shape)\n",
    "char_encoder = Character_level_encoder(len(id2lettre), 64)\n",
    "embeds = char_encoder(torch.from_numpy(data).long().squeeze())\n",
    "print(\"apres projection espace embedded: \", embeds.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le décodage des ${h_t}$  pour produire les ${h_{t+1}}$\n",
    "\n",
    "Il nous faut une classe décodeur pour arriver à produire à partir des ${h_1, h_2, ..., h_{T-1}}$ les ${h_2, h_3, ..., h_{T}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_cell(torch.nn.Module):\n",
    "    \"\"\" decode un etat caché \"\"\"\n",
    "    def __init__(self, latent, dim):\n",
    "        super(Decoder_cell, self).__init__()\n",
    "        # 1st param: nmbr de caractères, 2nd param: embedding dim\n",
    "        self.W = nn.Sequential(nn.Linear(latent, 16),\n",
    "                               nn.Tanh(),\n",
    "                               nn.Linear(16, dim), nn.Softmax(dim=2))\n",
    "        # doit pouvoir produire une classe à partir d'un état caché\n",
    "    def forward(self, h):\n",
    "        \"\"\" \"\"\"\n",
    "        return self.W(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut combiner toutes ces briques dans un modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_generator(torch.nn.Module):\n",
    "    \"\"\" Combines a character level embeddings encoder, a GRU, a decoder \"\"\"\n",
    "    def __init__(self, latent, dim, vocab_size, embedding_dim):\n",
    "        super(GRU_generator, self).__init__()\n",
    "        \n",
    "    def forward(self, sequences):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_RNN(X_train, y_train)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=240, shuffle=True)\n",
    "test_dataset = Dataset_RNN(X_test, y_test)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=240, shuffle=False)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # pas besoin de one-hot pour les labels avec cette fct là\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    for seq_batch, labels_batch in train_loader:\n",
    "        \n",
    "        embeds = char_encoder(seq_batch)\n",
    "        h = gru(embeds)\n",
    "        decoded = decoder(h)\n",
    "        \n",
    "        loss = criterion(decoded[:-1], labels_batch[1:])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
