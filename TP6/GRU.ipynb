{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 6 LSTMs & GRU: génération de séquences\n",
    "\n",
    "_Ismaël Bonneau_\n",
    "\n",
    "Ce notebook sert uniquement à présenter nos résultats, et les bouts de code intéressants dans le cadre de ce rapport. L'intégralité du code est contenu dans le fichier tp6.py.\n",
    "\n",
    "## But\n",
    "\n",
    "Nous avons dans le notebook précédent codé un RNN from scratch et nous l'avons appliqué sur une tâche de génération de séquence. Nous allons maintenant reprendre cette tâche et utiliser à la place du RNN un LSTM et un GRU, codés from scratch.\n",
    "\n",
    "<img src=\"../images/rnn_vs_lstm.png\" width=\"500\">\n",
    "\n",
    "## Données\n",
    "\n",
    "Le jeu de données suggéré dans l'énoncé est un discours de Donald Trump. Cependant, il est beaucoup plus drôle de travailler sur le script du seigneur des anneaux. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmovieever = pd.read_csv(\"../TP4/data/lord-of-the-rings-data/lotr_scripts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérons les lignes de dialogue des 3 films du seigneur des anneaux. Nous allons garder uniquement les répliques de Gandalf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>char</th>\n",
       "      <th>dialog</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>Now come the days of the King. May they be...</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>Hobbits!</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>Be careful. Even in defeat, Saruman is dangero...</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>No, we need him alive. We need him to talk.</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>Your treachery has already cost many lives. Th...</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     char                                             dialog  \\\n",
       "34          34  GANDALF      Now come the days of the King. May they be...   \n",
       "68          68  GANDALF                                         Hobbits!     \n",
       "72          72  GANDALF  Be careful. Even in defeat, Saruman is dangero...   \n",
       "74          74  GANDALF      No, we need him alive. We need him to talk.     \n",
       "78          78  GANDALF  Your treachery has already cost many lives. Th...   \n",
       "\n",
       "                      movie  \n",
       "34  The Return of the King   \n",
       "68  The Return of the King   \n",
       "72  The Return of the King   \n",
       "74  The Return of the King   \n",
       "78  The Return of the King   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = [\"GANDALF\", \"\\xa0GANDALF\", \"GAN DALF\", 'GANDALF VOICEOVER']\n",
    "bestmovieever[bestmovieever[\"char\"].isin(characters)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On nettoie un peu les lignes de dialogue:\n",
    "\n",
    "On sépare en phrases, et on élimine les phrases trop courtes (comme \"no.\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_tags, strip_numeric\n",
    "import re\n",
    "\n",
    "CUSTOM_FILTERS = [strip_tags, strip_multiple_whitespaces, strip_numeric]\n",
    "\n",
    "hey = list(bestmovieever[bestmovieever[\"char\"].isin(characters)][\"dialog\"])\n",
    "gandalf = []\n",
    "for d in hey:\n",
    "    mdr = \" \".join(preprocess_string(d, CUSTOM_FILTERS))\n",
    "    for ahaha in mdr.split(\".\"):\n",
    "        if ahaha != \"\":\n",
    "            x = ahaha.strip()\n",
    "            if (\"!\" != x[-1]) and (\"?\" != x[-1]):\n",
    "                x = x+\".\"\n",
    "            x = re.sub(r'^ , ', '', x)\n",
    "            x = re.sub(r'^, ', '', x)\n",
    "            x = re.sub(r'^,', '', x)\n",
    "            if len(x) > 8:\n",
    "                gandalf.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"End? No, the journey doesn't end here.\",\n",
       " 'Death is just another path, one that we all must take.',\n",
       " 'The grey rain curtain of this world rolls back and all turns to silvered glass.',\n",
       " 'And then you see it.',\n",
       " 'White shores and beyond, a far green country under a swift sunrise.',\n",
       " \"No it isn't.\",\n",
       " \"Saruman! You were deep in the enemy's counsel.\",\n",
       " 'Tell us what you know!',\n",
       " 'Send word to all our allies and to every corner of Middle Earth that still stands free.',\n",
       " 'The enemy moves against us.',\n",
       " 'We need to know where he will strike.',\n",
       " 'Peregrin Took.',\n",
       " \"I'll take that my lad! Quickly now!\",\n",
       " 'Retreat! The city is breached.',\n",
       " 'Fall back to the second level.',\n",
       " 'Get the women and children out.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gandalf[18:34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous allons travailler au niveau des caractères. \n",
    "\n",
    "il faut encoder chaque caractère sous forme d'id numérique (entier). On associe donc à chaque caractère un entier. le 0 servira au padding, et l'id _nb caractères+1_ servira à signaler la fin de séquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longueur max. de sequence: 188\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "max_len = len(gandalf[np.argmax([len(s) for s in gandalf])]) + 1 # +1 pour la fin de séquence\n",
    "print(\"longueur max. de sequence: {}\".format(max_len))\n",
    "\n",
    "LETTRES = set()\n",
    "for phrase in gandalf:\n",
    "    LETTRES.update(list(phrase))\n",
    "LETTRES.update(list(string.ascii_letters))\n",
    "id2lettre = dict(zip(range(1, len(LETTRES)+1),LETTRES))\n",
    "id2lettre[0]= '' # NULL CHARACTER for padding\n",
    "id2lettre[len(LETTRES)+1] = \"EOF\"\n",
    "lettre2id = dict(zip(id2lettre.values(), id2lettre.keys()))\n",
    "\n",
    "def normalize(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if c in LETTRES)\n",
    "def string2code(s):\n",
    "    base = [lettre2id[c] for c in normalize(s)] + [lettre2id[\"EOF\"]]\n",
    "    if len(base) < max_len:\n",
    "        padding = [0] * (max_len - len(base))\n",
    "    else:\n",
    "        padding = []\n",
    "    return base + padding + [0]\n",
    "def code2string(t):\n",
    "    if type(t) != list:\n",
    "        t = t.tolist()\n",
    "    return ''.join(id2lettre[i] for i in t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple de phrase transformée en suite d'entiers:\n",
    "\n",
    "On voit que l'on a ajouté du padding (des 0) à la fin des phrases pour avoir des sequences de longueur identique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go back to the abyss! Fall into the nothingness that awaits you and your master!\n",
      "[3, 12, 24, 45, 27, 13, 29, 24, 51, 12, 24, 51, 38, 55, 24, 27, 45, 50, 47, 47, 37, 24, 35, 27, 22, 22, 24, 17, 6, 51, 12, 24, 51, 38, 55, 24, 6, 12, 51, 38, 17, 6, 36, 6, 55, 47, 47, 24, 51, 38, 27, 51, 24, 27, 1, 27, 17, 51, 47, 24, 50, 12, 34, 24, 27, 6, 5, 24, 50, 12, 34, 39, 24, 33, 27, 47, 51, 55, 39, 37, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(gandalf[38])\n",
    "print(string2code(gandalf[38]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pas besoin de one-hot encoding car on va utiliser le module nn.Embeddings\n",
    "\n",
    "On utilise _np.exand_dims_ pour avoir une matrice en 3 dimensions _nb sequences x longueur sequence x dimension données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 189, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.array([np.array(string2code(s)) for s in gandalf])\n",
    "data = np.expand_dims(data, axis=2)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le GRU que nous avons codé attend en entrée des matrices de taille _longueur sequence x nb sequences (batch) x dimension données_. On va donc swaper les dimensions 0 et 1 de notre array de séquences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 417, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.swapaxes(data, 0, 1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà les donneés prêtes à être ingérées par le modèle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle\n",
    "\n",
    "Cette fois-ci, on introduit la supervision à chaque étape: au lieu de devoir encoder correctement une classe dans l'état ${h_T}$, le modèle doit réussir à produire ${x_t}$ à partir de ${h_{t-1}}$ à chaque étape. Chaque \"cellule\" du GRU déplié doit donc appliquer un décodeur sur l'état ${h_{t-1}}$ qu'elle reçoit en entrée.\n",
    "\n",
    "Le fait que l'on utilise des caractères rajoute une difficulté supplémentaire: il va falloir en même temps calculer une projection des caractères dans un espace continu (embedding).\n",
    "\n",
    "L'entrainement va fonctionner comme ceci:\n",
    "\n",
    "- On traite le batch de sequences avec une passe de forward.\n",
    "- On récupère l'historique des ${h_1}$, ..., ${h_{T-1}}$ calculés par le réseau.\n",
    "- On décode l'historique.\n",
    "- On calcule la loss (cross entropy) sur les valeurs décodées qui doivent correspondre à ${h_2}$, ..., ${h_{T}}$\n",
    "- On masque la loss aux endroits qui correspondent au padding pour chaque batch, et on applique la backward propagation.\n",
    "\n",
    "\n",
    "<img src=\"../images/gru.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    \"\"\"docstring for GRU\"\"\"\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(GRU, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.W_update_x = nn.Linear(input_dim, latent_dim)\n",
    "        self.W_update_h = nn.Linear(latent_dim, latent_dim)\n",
    "        \n",
    "        self.W_reset_x = nn.Linear(input_dim, latent_dim)\n",
    "        self.W_reset_h = nn.Linear(latent_dim, latent_dim)\n",
    "        \n",
    "        self.W_x = nn.Linear(input_dim, latent_dim)\n",
    "        self.W_h = nn.Linear(latent_dim, latent_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def one_step(self, x, h):\n",
    "        \"\"\" one step for one Xt and Ht-1 \"\"\"\n",
    "        zt = self.sigmoid(self.W_update_x(x) + self.W_update_h(h))\n",
    "        rt = self.sigmoid(self.W_reset_x(x) + self.W_reset_h(h))\n",
    "        ht = (1 - zt) * h + zt * self.tanh(self.W_x(x) + self.W_h(rt * h))\n",
    "        return ht\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\" forward on the whole sequence \"\"\"\n",
    "        historique = []\n",
    "        if h is None:\n",
    "            ht = torch.zeros(x.size()[1], self.latent_dim)\n",
    "        for xt in x:\n",
    "            # ht: (batch x latent)\n",
    "            ht = self.one_step(xt, ht)\n",
    "            historique.append(ht)\n",
    "        return historique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character_level_encoder(torch.nn.Module):\n",
    "    \"\"\" projette les caractères dans un embedding \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Character_level_encoder, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) #apprendre des embeddings de caractère en même temps\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_cell(torch.nn.Module):\n",
    "    \"\"\" decode un etat caché \"\"\"\n",
    "    def __init__(self, latent, dim):\n",
    "        super(Decoder_cell, self).__init__()\n",
    "        # 1st param: nmbr de caractères, 2nd param: embedding dim\n",
    "        self.W = nn.Sequential(nn.Linear(latent, 16),\n",
    "                               nn.Tanh(),\n",
    "                               nn.Linear(16, dim), nn.Softmax(dim=2))\n",
    "        # doit pouvoir produire une classe à partir d'un état caché\n",
    "    def forward(self, h):\n",
    "        \"\"\" \"\"\"\n",
    "        return self.W(h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
