{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 4 RNNs: classification de séquences, forecasting, génération de séquences (suite)\n",
    "\n",
    "_Ismaël Bonneau_\n",
    "\n",
    "Ce notebook sert uniquement à présenter nos résultats, et les bouts de code intéressants dans le cadre de ce rapport. L'intégralité du code est contenu dans le fichier tp4.py.\n",
    "\n",
    "## But\n",
    "\n",
    "Nous avons dans le notebook précédent codé un RNN from scratch et nous l'avons appliqué sur une tâche de classification de séquence. Nous allons maintenant reprendre ce RNN et réaliser une tâche de génération de séquence.\n",
    "\n",
    "## Données\n",
    "\n",
    "Le jeu de données suggéré dans l'énoncé est un discours de Donald Trump. Cependant, il est beaucoup plus drôle de travailler sur le script du seigneur des anneaux. \n",
    "\n",
    "<img src=\"boromir.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import models\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmovieever = pd.read_csv(\"data/lord-of-the-rings-data/lotr_scripts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérons les lignes de dialogue des 3 films du seigneur des anneaux. Nous allons garder uniquement les répliques de Gandalf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>char</th>\n",
       "      <th>dialog</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>Now come the days of the King. May they be...</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>Hobbits!</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>Be careful. Even in defeat, Saruman is dangero...</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>No, we need him alive. We need him to talk.</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>GANDALF</td>\n",
       "      <td>Your treachery has already cost many lives. Th...</td>\n",
       "      <td>The Return of the King</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     char                                             dialog  \\\n",
       "34          34  GANDALF      Now come the days of the King. May they be...   \n",
       "68          68  GANDALF                                         Hobbits!     \n",
       "72          72  GANDALF  Be careful. Even in defeat, Saruman is dangero...   \n",
       "74          74  GANDALF      No, we need him alive. We need him to talk.     \n",
       "78          78  GANDALF  Your treachery has already cost many lives. Th...   \n",
       "\n",
       "                      movie  \n",
       "34  The Return of the King   \n",
       "68  The Return of the King   \n",
       "72  The Return of the King   \n",
       "74  The Return of the King   \n",
       "78  The Return of the King   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmovieever[bestmovieever[\"char\"] == \"GANDALF\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On nettoie un peu les lignes de dialogue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_tags\n",
    "import re\n",
    "\n",
    "CUSTOM_FILTERS = [strip_tags, strip_multiple_whitespaces]\n",
    "\n",
    "hey = list(bestmovieever[bestmovieever[\"char\"] == \"GANDALF\"][\"dialog\"])\n",
    "gandalf = []\n",
    "for d in hey:\n",
    "    mdr = \" \".join(preprocess_string(d, CUSTOM_FILTERS))\n",
    "    for ahaha in mdr.split(\".\"):\n",
    "        if ahaha != \"\":\n",
    "            x = ahaha.strip()+\".\"\n",
    "            x = re.sub(r'^ , ', '', x)\n",
    "            x = re.sub(r'^, ', '', x)\n",
    "            x = re.sub(r'^,', '', x)\n",
    "            gandalf.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous allons travailler au niveau des caractères. \n",
    "\n",
    "il faut encoder chaque caractère sous forme d'id numérique (entier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longueur max. de sequence: 187\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "max_len = len(gandalf[np.argmax([len(s) for s in gandalf])])\n",
    "print(\"longueur max. de sequence: {}\".format(max_len))\n",
    "\n",
    "# use $ as a end-of-sequence character and @ as a start-of-sequence\n",
    "LETTRES = string.ascii_letters + '!\"&\\'(),-./:;?[\\\\]' + ' '\n",
    "id2lettre = dict(zip(range(1, len(LETTRES)+1),LETTRES))\n",
    "id2lettre[0]= '' ##NULL CHARACTER\n",
    "lettre2id = dict(zip(id2lettre.values(), id2lettre.keys()))\n",
    "\n",
    "def normalize(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if c in LETTRES)\n",
    "def string2code(s):\n",
    "    base = [lettre2id[c] for c in normalize(s)]\n",
    "    if len(base) < max_len:\n",
    "        padding = [0] * (max_len - len(base))\n",
    "    else:\n",
    "        padding = []\n",
    "    return base + padding + [0]\n",
    "def code2string(t):\n",
    "    if type(t) != list:\n",
    "        t = t.tolist()\n",
    "    return ''.join(id2lettre[i] for i in t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now come the days of the King.\n",
      "[40, 15, 23, 69, 3, 15, 13, 5, 69, 20, 8, 5, 69, 4, 1, 25, 19, 69, 15, 6, 69, 20, 8, 5, 69, 37, 9, 14, 7, 61, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(gandalf[0])\n",
    "print(string2code(gandalf[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passage en one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avant one-hot encoding:  (424, 188)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = np.array([np.array(string2code(s)) for s in gandalf])\n",
    "print(\"avant one-hot encoding: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions maintenant:  (424, 188, 70)\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded = []\n",
    "for elt in data:\n",
    "    onehotencoder = OneHotEncoder(sparse=False, categories=[range(len(LETTRES)+1)])\n",
    "    one_hot_encoded.append(onehotencoder.fit_transform(elt.reshape(-1, 1)))\n",
    "one_hot_encoded = np.array(one_hot_encoded)\n",
    "print(\"dimensions maintenant: \", one_hot_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le RNN que nous avons codé attend en entrée des matrices de taille sequence_length x batch x dim. On va donc swaper les dimensions 0 et 1 de notre array de séquences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 424, 70)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.swapaxes(one_hot_encoded, 0, 1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle\n",
    "\n",
    "Cette fois-ci, on introduit la supervision à chaque étape: au lieu de devoir encoder correctement une classe dans l'état ${h_T}$, le modèle doit réussir à produire ${h_t}$ à partir de ${h_{t-1}}$ à chaque étape. Chaque \"cellule\" du RNN déplié doit donc appliquer un décodeur sur l'état ${h_{t-1}}$ qu'elle reçoit en entrée.\n",
    "\n",
    "Le fait que l'on utilise des caractères rajoute une difficulté supplémentaire: il va falloir en même temps calculer une projection des caractères dans un espace continu (embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    \"\"\"docstring for RNN\"\"\"\n",
    "    def __init__(self, dim, latent):\n",
    "        super(RNN, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.latent = latent\n",
    "        self.Wx = torch.nn.Linear(dim, latent)\n",
    "        self.Wh = torch.nn.Linear(latent, latent)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\" x: sequence_length x batch x dim \n",
    "            h: batch x latent\n",
    "            returns: length x batch x latent Tensor\"\"\"\n",
    "        historique = []\n",
    "        # pour chaque instant de la sequence:\n",
    "        if h is None:\n",
    "            ht = torch.zeros(x.size()[1], self.latent)\n",
    "            historique.append(ht)\n",
    "        for i, xt in enumerate(x):\n",
    "            # ht: (batch x latent)\n",
    "            ht = self.one_step(xt, ht)\n",
    "            historique.append(ht) # Ne pas enregistrer les h0\n",
    "        return historique\n",
    "\n",
    "    def one_step(self, x, h):\n",
    "        \"\"\" x: batch x dim \n",
    "            h: batch x latent\n",
    "            returns: batch x latent Tensor \"\"\"\n",
    "        return torch.nn.functional.leaky_relu(self.Wx(x) + self.Wh(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_cell(torch.nn.Module):\n",
    "    \"\"\" decode un etat caché \"\"\"\n",
    "    def __init__(self, latent, dim):\n",
    "        super(Decoder_cell, self).__init__()\n",
    "        self.W = nn.Sequential(nn.Linear(latent, 16),\n",
    "                               nn.Tanh(),\n",
    "                               nn.Linear(16, dim), nn.Softmax(dim=2))\n",
    "        # doit pouvoir produire une classe à partir d'un état caché\n",
    "        \n",
    "    def forward(self, h):\n",
    "        \"\"\" \"\"\"\n",
    "        return self.W(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(X_train.shape[2], 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.stack(rnn(torch.from_numpy(X_train).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder_cell(32, X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "khabib = decoder(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([189, 424, 70])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khabib.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([188, 424, 70])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khabib[1:,:,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-e657a4a3432d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkhabib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 942\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or more dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[1;32m   1869\u001b[0m                          .format(input.size(0), target.size(0)))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "criterion(khabib[1:,:,:], X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
