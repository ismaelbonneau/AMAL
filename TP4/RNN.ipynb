{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 4 RNNs: classification de séquences, forecasting, génération de séquences, one-hot encoding\n",
    "\n",
    "_Ismaël Bonneau_\n",
    "\n",
    "Ce notebook sert uniquement à présenter nos résultats, et les bouts de code intéressants dans le cadre de ce rapport. L'intégralité du code est contenu dans le fichier tp4.py.\n",
    "\n",
    "## But\n",
    "\n",
    "- implémenter un RNN en pytorch\n",
    "- réaliser une tâche de classification de séquence\n",
    "- réaliser une tâche de forecasting (prédiction de caracètre)\n",
    "\n",
    "## Données\n",
    "\n",
    "2 jeux de données sont fournis: un jeu de relevés de température à travers 31 villes des Etats Unis et du Canada, qui pourra servir à de la classification de séquence (many to one), par exemple pour prédire une ville sachant une séquence de température, ou à du forecasting, en préduisant la température à ${t+1}$. L'autre est un jeu de données de discours de trump, qui pourra servir essentiellement à du forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import models\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb exemples: 11115, cities: 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Vancouver</th>\n",
       "      <th>Portland</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Seattle</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>Las Vegas</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>...</th>\n",
       "      <th>Detroit</th>\n",
       "      <th>Jacksonville</th>\n",
       "      <th>Charlotte</th>\n",
       "      <th>Miami</th>\n",
       "      <th>Pittsburgh</th>\n",
       "      <th>Toronto</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>New York</th>\n",
       "      <th>Montreal</th>\n",
       "      <th>Boston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>284.630000</td>\n",
       "      <td>282.080000</td>\n",
       "      <td>289.480000</td>\n",
       "      <td>281.800000</td>\n",
       "      <td>291.870000</td>\n",
       "      <td>291.530000</td>\n",
       "      <td>293.410000</td>\n",
       "      <td>296.600000</td>\n",
       "      <td>285.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>284.030000</td>\n",
       "      <td>298.170000</td>\n",
       "      <td>288.650000</td>\n",
       "      <td>299.720000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>286.260000</td>\n",
       "      <td>285.630000</td>\n",
       "      <td>288.220000</td>\n",
       "      <td>285.830000</td>\n",
       "      <td>287.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>284.629041</td>\n",
       "      <td>282.083252</td>\n",
       "      <td>289.474993</td>\n",
       "      <td>281.797217</td>\n",
       "      <td>291.868186</td>\n",
       "      <td>291.533501</td>\n",
       "      <td>293.403141</td>\n",
       "      <td>296.608509</td>\n",
       "      <td>285.154558</td>\n",
       "      <td>...</td>\n",
       "      <td>284.069789</td>\n",
       "      <td>298.205230</td>\n",
       "      <td>288.650172</td>\n",
       "      <td>299.732518</td>\n",
       "      <td>281.024767</td>\n",
       "      <td>286.262541</td>\n",
       "      <td>285.663208</td>\n",
       "      <td>288.247676</td>\n",
       "      <td>285.834650</td>\n",
       "      <td>287.186092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>284.626998</td>\n",
       "      <td>282.091866</td>\n",
       "      <td>289.460618</td>\n",
       "      <td>281.789833</td>\n",
       "      <td>291.862844</td>\n",
       "      <td>291.543355</td>\n",
       "      <td>293.392177</td>\n",
       "      <td>296.631487</td>\n",
       "      <td>285.233952</td>\n",
       "      <td>...</td>\n",
       "      <td>284.173965</td>\n",
       "      <td>298.299595</td>\n",
       "      <td>288.650582</td>\n",
       "      <td>299.766579</td>\n",
       "      <td>281.088319</td>\n",
       "      <td>286.269518</td>\n",
       "      <td>285.756824</td>\n",
       "      <td>288.326940</td>\n",
       "      <td>285.847790</td>\n",
       "      <td>287.231672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>284.624955</td>\n",
       "      <td>282.100481</td>\n",
       "      <td>289.446243</td>\n",
       "      <td>281.782449</td>\n",
       "      <td>291.857503</td>\n",
       "      <td>291.553209</td>\n",
       "      <td>293.381213</td>\n",
       "      <td>296.654466</td>\n",
       "      <td>285.313345</td>\n",
       "      <td>...</td>\n",
       "      <td>284.278140</td>\n",
       "      <td>298.393961</td>\n",
       "      <td>288.650991</td>\n",
       "      <td>299.800641</td>\n",
       "      <td>281.151870</td>\n",
       "      <td>286.276496</td>\n",
       "      <td>285.850440</td>\n",
       "      <td>288.406203</td>\n",
       "      <td>285.860929</td>\n",
       "      <td>287.277251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-01 17:00:00</td>\n",
       "      <td>284.622911</td>\n",
       "      <td>282.109095</td>\n",
       "      <td>289.431869</td>\n",
       "      <td>281.775065</td>\n",
       "      <td>291.852162</td>\n",
       "      <td>291.563063</td>\n",
       "      <td>293.370249</td>\n",
       "      <td>296.677445</td>\n",
       "      <td>285.392738</td>\n",
       "      <td>...</td>\n",
       "      <td>284.382316</td>\n",
       "      <td>298.488326</td>\n",
       "      <td>288.651401</td>\n",
       "      <td>299.834703</td>\n",
       "      <td>281.215421</td>\n",
       "      <td>286.283473</td>\n",
       "      <td>285.944057</td>\n",
       "      <td>288.485467</td>\n",
       "      <td>285.874069</td>\n",
       "      <td>287.322831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime   Vancouver    Portland  San Francisco     Seattle  \\\n",
       "0  2012-10-01 13:00:00  284.630000  282.080000     289.480000  281.800000   \n",
       "1  2012-10-01 14:00:00  284.629041  282.083252     289.474993  281.797217   \n",
       "2  2012-10-01 15:00:00  284.626998  282.091866     289.460618  281.789833   \n",
       "3  2012-10-01 16:00:00  284.624955  282.100481     289.446243  281.782449   \n",
       "4  2012-10-01 17:00:00  284.622911  282.109095     289.431869  281.775065   \n",
       "\n",
       "   Los Angeles   San Diego   Las Vegas     Phoenix  Albuquerque  ...  \\\n",
       "0   291.870000  291.530000  293.410000  296.600000   285.120000  ...   \n",
       "1   291.868186  291.533501  293.403141  296.608509   285.154558  ...   \n",
       "2   291.862844  291.543355  293.392177  296.631487   285.233952  ...   \n",
       "3   291.857503  291.553209  293.381213  296.654466   285.313345  ...   \n",
       "4   291.852162  291.563063  293.370249  296.677445   285.392738  ...   \n",
       "\n",
       "      Detroit  Jacksonville   Charlotte       Miami  Pittsburgh     Toronto  \\\n",
       "0  284.030000    298.170000  288.650000  299.720000  281.000000  286.260000   \n",
       "1  284.069789    298.205230  288.650172  299.732518  281.024767  286.262541   \n",
       "2  284.173965    298.299595  288.650582  299.766579  281.088319  286.269518   \n",
       "3  284.278140    298.393961  288.650991  299.800641  281.151870  286.276496   \n",
       "4  284.382316    298.488326  288.651401  299.834703  281.215421  286.283473   \n",
       "\n",
       "   Philadelphia    New York    Montreal      Boston  \n",
       "0    285.630000  288.220000  285.830000  287.170000  \n",
       "1    285.663208  288.247676  285.834650  287.186092  \n",
       "2    285.756824  288.326940  285.847790  287.231672  \n",
       "3    285.850440  288.406203  285.860929  287.277251  \n",
       "4    285.944057  288.485467  285.874069  287.322831  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures_csv = pd.read_csv(\"data/tempAMAL_train.csv\")\n",
    "print(\"Nb exemples: {}, cities: {}\".format(temperatures_csv.shape[0], temperatures_csv.shape[1]))\n",
    "\n",
    "temperatures_csv.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construisons le jeu de données\n",
    "\n",
    "On va construire un dataset et un dataLoader associé qui vont contenir nos séquences et batches associés. On procède comme suit:\n",
    "\n",
    "- On sample au hasard 10 villes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 20, 1) (600, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "nbclass = 10 # prendre nbclass = 10 villes pour la tache de classif de séquences\n",
    "seq_len = 20 # prendre une longueur de séquence de taille fixe pour le moment\n",
    "nb_sequences = 300 # prendre 300 séquences par ville\n",
    "\n",
    "cities = np.random.choice(temperatures_csv.columns[1:], nbclass, replace=False) # ne pas sélectionner le datetime\n",
    "\n",
    "def sample_sequence(city):\n",
    "    start = np.random.randint(0, temperatures_csv.shape[0] - seq_len)\n",
    "    return np.array(temperatures_csv[city][start:start + seq_len])\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "for i, city in enumerate(cities):\n",
    "    j = 0\n",
    "    while j < nb_sequences:\n",
    "        s = sample_sequence(city)\n",
    "        if not np.isnan(s).any(): # certains nan peuvent être présents dans le dataframe\n",
    "            sequences.append(s)\n",
    "            labels.append(i)\n",
    "            j += 1\n",
    "        \n",
    "sequences = np.array(sequences)\n",
    "labels = np.array(labels)\n",
    "sequences /= np.max(sequences) # normaliser\n",
    "#sequences, labels = shuffle(sequences, labels, random_state=1997) # shuffle lines\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=1997)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2) # pour créer une dimension supplémentaire de taille 1\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chicago', 'Albuquerque', 'Pittsburgh', 'Miami', 'Denver',\n",
       "       'Minneapolis', 'Saint Louis', 'Indianapolis', 'Las Vegas',\n",
       "       'San Diego'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le RNN que nous avons codé attend en entrée des matrices de taille sequence_length x batch x dim. Dans notre cas où nous avons pris des séquences de taille 20, on aurait donc des matrices de taille 20 x batch x 1, car nos données sont en dimension 1.\n",
    "\n",
    "On va donc swaper les dimensions 0 et 1 de notre array de séquences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 20, 1)\n",
      "(20, 2400, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = np.swapaxes(X_train,0,1)\n",
    "X_test = np.swapaxes(X_test,0,1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un petit dataset pour le RNN s'impose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Dataset_RNN(Dataset):\n",
    "    \"\"\"Dataset avec la taille de batch en axis 1 au lieu de 0.\n",
    "        Pas mal pour notre RNN\"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        super(Dataset_RNN, self).__init__()\n",
    "        self.labels = torch.from_numpy(y)\n",
    "        self.data = torch.from_numpy(x).float()\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[:,index,:], self.labels[index]\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles\n",
    "\n",
    "### Le code du RNN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    \"\"\"docstring for RNN\"\"\"\n",
    "    def __init__(self, dim, latent):\n",
    "        super(RNN, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.latent = latent\n",
    "        self.Wx = torch.nn.Linear(dim, latent)\n",
    "        self.Wh = torch.nn.Linear(latent, latent)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\" x: sequence_length x batch x dim \n",
    "            h: batch x latent\n",
    "            returns: length x batch x latent Tensor\"\"\"\n",
    "        historique = []\n",
    "        # pour chaque instant de la sequence:\n",
    "        if h is None:\n",
    "            ht = torch.zeros(x.size()[1], self.latent)\n",
    "            historique.append(ht.numpy())\n",
    "        for i, xt in enumerate(x):\n",
    "            # ht: (batch x latent)\n",
    "            ht = self.one_step(xt, ht)\n",
    "            if i > 0:\n",
    "                historique.append(ht) # Ne pas enregistrer les h0\n",
    "\n",
    "        return torch.Tensor(historique)\n",
    "\n",
    "    def one_step(self, x, h):\n",
    "        \"\"\" x: batch x dim \n",
    "            h: batch x latent\n",
    "            returns: batch x latent Tensor \"\"\"\n",
    "        return torch.nn.functional.leaky_relu(torch.add(self.Wx(x), self.Wh(h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le code du decoder qui va permettre de passer de ${h_{T}}$ à une classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    \"\"\" simple Neural Net \"\"\"\n",
    "    def __init__(self, inSize, outSize, layers=[]):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for x in layers:\n",
    "            self.layers.append(nn.Linear(inSize, x))\n",
    "            inSize = x\n",
    "        self.layers.append(nn.Linear(inSize, outSize))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers[0](x)\n",
    "        for i in range(1, len(self.layers)):\n",
    "            x = torch.nn.functional.leaky_relu(x)\n",
    "            x = self.layers[i](x)\n",
    "        return torch.nn.functional.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequenceClassifier: contient un RNN et un decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassifier(torch.nn.Module):\n",
    "    \"\"\" \"\"\"\n",
    "    def __init__(self, dim, latent, nbClass):\n",
    "        super(SequenceClassifier, self).__init__()\n",
    "        self.rnn = RNN(dim, latent)\n",
    "        self.decoder = Decoder(latent, nbClass, layers=[8, 16, 8])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" \"\"\"\n",
    "        hT = self.rnn(x)[-1]\n",
    "        return self.decoder(hT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expérimentations\n",
    "\n",
    "Nous allons expérimenter avec le réseau de neurones.\n",
    "\n",
    "- Criterion: Cross entropy loss\n",
    "- Validation mesure: accuracy (classes équilibrées)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_RNN(X_train, y_train)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=240, shuffle=True)\n",
    "test_dataset = Dataset_RNN(X_test, y_test)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=240, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def accuracy(model, x, labels):\n",
    "    outputs = model(x)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    c = (predicted == labels).squeeze().sum()\n",
    "    return c.item() / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ismael/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10291666666666666\n",
      "epoch 0 training loss 2.3030203104019167\n",
      "0.10291666666666668\n",
      "epoch 1 training loss 2.3030049324035646\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-230956b6b7c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseq_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0maccuracies_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies_sum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-d8ac91e0323f>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(model, x, labels)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-4c2e09544547>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"\"\" \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mhT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5c99cc0bc29c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mhistorique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Ne pas enregistrer les h0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistorique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    434\u001b[0m                           \u001b[0;34m'iterations executed (and might lead to errors or silently give '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                           'incorrect results).', category=RuntimeWarning)\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "latentdim = 32\n",
    "inputdim = 1 # on input des températures => scalaires\n",
    "\n",
    "rnn = SequenceClassifier(inputdim, latentdim, len(cities))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # pas besoin de one-hot pour les labels avec cette fct là\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for e in range(epochs):\n",
    "    losses = []\n",
    "    for seq_batch, label_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = rnn(seq_batch.permute(1, 0, 2))\n",
    "        loss = criterion(preds, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    accuracies_sum = 0\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for seq_batch, label_batch in train_dataloader:\n",
    "            rnn.eval()\n",
    "            accuracies_sum += accuracy(rnn, seq_batch.permute(1, 0, 2), label_batch)\n",
    "            i += 1\n",
    "    print(accuracies_sum / i)\n",
    "        \n",
    "    #writer.add_scalar('Loss/train', epoch_losses[-1], e)\n",
    "    print(\"epoch {} training loss {}\".format(e, np.mean(losses)))\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './rnn.pth'\n",
    "torch.save(rnn.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
