{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 3: Implémentation de module, Gestion de données, Checkpointing et GPU\n",
    "\n",
    "_Ismaël Bonneau & Issam Benamara_\n",
    "\n",
    "Le vrai code, comme les imports, le chargement des données se trouve dans le fichier _tp3.py_. Ce rapport sert à présenter l'avancée de notre travail et notre compréhension du sujet.\n",
    "\n",
    "### Dataset & Dataloader\n",
    "\n",
    "Nous avons exploré les possibilités des dataloaders et datasets.\n",
    "\n",
    "Un ***Dataset*** en pytorch: classe encapsulant des données labelisées (ou non) X et Y.\n",
    "\n",
    "\n",
    "Un ***DataLoader***: interface de manipulation d'un dataset fournissant un itérateur dessus et de nombreuses options utiles. Parmi elles, on peut noter:\n",
    "\n",
    "- ***batch_size***, qui permet de parcourir le dataloader comme un itérable sur le dataset en nous renvoyant des batches x, y de la taille spécifiée. Très utile. \n",
    "- ***shuffle***, qui dit au dataloader de re mélanger dans un ordre random les exemples du dataset à chaque itération dessus ( = chaque _epoch_ de l'apprentissage)\n",
    "- ***sampler et batch_sampler*** qui permettent de spécifier la méthode de sampling des exemples.\n",
    "- ***collate_fn*** permet de spécifier la façon dont on veut assembler les données (par défaut, renvoie un tuple (exemple(s), label(s). \n",
    "\n",
    "#### Voici un exemple de dataset pour MNIST qui renvoie un couple (Tenseur 1D, label) pour chaque image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_MNIST(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(Dataset_MNIST, self).__init__()\n",
    "        self.labels = torch.from_numpy(y)\n",
    "        self.data = torch.from_numpy(x).float()\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dataloader associé avec une taille de batch de 40 sera créé ainsi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_MNIST(X_train, y_train)\n",
    "trainloader = DataLoader(dataset=train_dataset, batch_size=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation d'un tied auto-encoder\n",
    "\n",
    "Un auto encoder permet d'encoder des objets dans un espace de dimension plus petite, pour en créer une représentation de plus haut niveau. On guide la construction de cet espace en cherchant à reconstruire les objets de départ d'après l'espace latent de façon la plus précise possible. \n",
    "\n",
    "Dans le cas d'un tied auto-encoder, les paramètres servant à l'encodage sont les mêmes que ceux servant au décodage. Cela présente plusieurs avantages:\n",
    "\n",
    "- Cela fait moins de paramètres à apprendre.\n",
    "- Il s'agit d'une façon de régulariser.\n",
    "- C'est au final très proche d'une PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiedAutoEncoder(nn.Module):\n",
    "    \"\"\" tied AutoEncoder: encoder and decoder share weights\"\"\"\n",
    "    def __init__(self, input_dim, latent):\n",
    "        super(TiedAutoEncoder, self).__init__()\n",
    "        self.W = torch.nn.Parameter(torch.randn(input_dim, latent), requires_grad=True)\n",
    "        self.b1 = torch.nn.Parameter(torch.randn(1), requires_grad=True)# bias for encoder\n",
    "        self.b2 = torch.nn.Parameter(torch.randn(1), requires_grad=True)# bias for decoder\n",
    "\n",
    "    def encode(self, x):\n",
    "        return nn.functional.relu(x @ self.W + self.b1)\n",
    "\n",
    "    def decode(self, x):\n",
    "        return torch.sigmoid(x @ self.W.t() + self.b2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On pourra comparer avec un auto encoder classique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \"\"\" classical & simple AutoEncoder \"\"\"\n",
    "    def __init__(self, input_dim, latent):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = torch.nn.Linear(input_dim, latent)\n",
    "        self.decoder = torch.nn.Linear(latent, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        return nn.functional.relu(self.encoder(x))\n",
    "\n",
    "    def decode(self, x):\n",
    "        return torch.sigmoid(self.decoder(x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU & checkpoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, model, optim):\n",
    "    self.model = model\n",
    "    self.optim = optim\n",
    "    self.epoch, self.iteration = 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campagne d'expériences:\n",
    "\n",
    "- Evaluer l'influence de la taille de l'espace latent dans la qualité de la reconstruction\n",
    "- Comparer Tied Autoencoder et Autoencoder classique\n",
    "\n",
    "\n",
    "Pour cette campagne d'expériences, on prendra les données MNIST, qui sont des images d'écriture manuscrite de chiffres entre 0 et 9. Ces images sont en taille 28x28 pixels\n",
    "\n",
    "\n",
    "| modèle        | dimension 10          | dimension 50  | dimension 100  | dimension 300  |\n",
    "| ------------- |:-------------:| -----:| -----:| -----:|\n",
    "| Tied AutoEncoder      | 0.0304 | 0.0094 | 0.0029 | 0.0026\n",
    "| AutoEncoder     | 0.0291      |   0.0079 | 0.0043 | 0.004 |\n",
    "\n",
    "Comme attendu, plus l'espace latent est grand, mieux on encode l'information et mieux on arrive à reconstruire l'image de départ. En revanche, un espace latent trop grand favorisera le surapprentissage.\n",
    "\n",
    "> On remarque bien que le tied auto encoder fait mieux en test que l'auto encoder en grande dimension: il agit comme mode de régularisation. Cependant, en petite dimension, l'auto encoder est meilleur en moyenne.\n",
    "\n",
    "<img src=\"encoder_dim5.png\" width=\"600\">\n",
    "\n",
    "<img src=\"encoder_dim100.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le tied autoencoder:\n",
    "\n",
    "<img src=\"tiedautoencoder.png\" width=\"800\">\n",
    "\n",
    "### Pour l'autoencoder classique:\n",
    "\n",
    "<img src=\"autoencoder.png\" width=\"800\">\n",
    "\n",
    "> On converge beaucoup plus rapidement avec un auto encoder classique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pire_vs_meilleur_10.png\" width=\"600\">\n",
    "\n",
    "<img src=\"pire_vs_meilleur_100.png\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
